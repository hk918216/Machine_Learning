{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6310aa5b",
   "metadata": {},
   "source": [
    "## 트리의 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc81c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정형데이터에 가장 뛰어난 성능을 보이는 모델들\n",
    "# 앙상블 모델들은 결정트리(Decision Tree)를 기반으로 만들어짐\n",
    "# 앙상블 모델들\n",
    "#  - 랜덤포레스트(Random Forest)\n",
    "#  - 엑스트라 트리(Extra Trees)\n",
    "#  - 그레디언트 부스팅(Gradient Boosting)\n",
    "#  - 히스토그램 기반 그레디언트 부스팅(Histogram-base Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da668f65",
   "metadata": {},
   "source": [
    "## 랜덤포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd19dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 앙상블 모델 중에 가장 대표격 모델로 사용됨\n",
    "# - 안정적인 성능으로 널리 사용됨\n",
    "# - 앙상블 모델 중에 가장 먼저 시도하는 모델이라고 보면 됨\n",
    "# - 훈련데이터에서 과대적합되는 것을 막아줌\n",
    "# - 검증데이터와 데스트데이터에서 안정적인 성능을 얻을 수 있음\n",
    "\n",
    "### 학습 개념\n",
    "# - 결정트리 하나하나를 랜덤하게 만들어서 숲을 만듦\n",
    "# - 훈련데이터에서 랜덤하게 샘플을 추출해 훈련을 완료한 후 다시 원본 훈련데이터에 반환\n",
    "# - 랜덤하게 추출 시 이전에 사용된 샘플을 사용할 수도 있음.\n",
    "#   (중복 허용)\n",
    "\n",
    "### 부트스트랩 샘플(Bootstrap Sample)\n",
    "# - 위에 설명한 랜덤한 샘플 추출 시 중복을 허용하여 데이터를 샘플링 하는 방식\n",
    "# - 샘풀 추출 방식\n",
    "# 1. 원본에서 랜덤 샘플 추출\n",
    "# 2. 훈련 이후 사용이 끝나면 원본에 반환\n",
    "# 3. 다시 원본에서 샘플 추출, 이때 중복값 추출될 수 있음\n",
    "#  위 순서를 반복하면서 샘플링 통해 훈련하는 방식을 랜덤포레스트가 적용\n",
    "\n",
    "### *** 랜덤포레스트는 교차검증을 허용함 *** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb487ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4872, 3)\n",
      "(1625, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('./data/08_wine.csv')\n",
    "\n",
    "# 독립/종속변수 분리\n",
    "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbc6ea",
   "metadata": {},
   "source": [
    "### 훈련모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8067bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.23727798, 0.26207328, 0.24305344, 0.25969148, 0.28168511]), 'score_time': array([0.05032182, 0.03377819, 0.03663635, 0.03333354, 0.03539014]), 'test_score': array([0.88      , 0.90051282, 0.90349076, 0.89014374, 0.88295688]), 'train_score': array([0.99743392, 0.99692071, 0.99846075, 0.99820421, 0.99820421])}\n",
      "=============\n",
      "0.997844759088341 0.8914208392565683\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트 클래스(모델) : RandomForestClassifier()\n",
    "# 교차검증 : cross_validate()\n",
    "# 교차검증 후 훈련검증결과와 테스트검증결과 확인\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 랜덤포레스트 객체생성 : 코어 모두 사용\n",
    "rf = RandomForestClassifier(n_jobs = -1, random_state=42)\n",
    "\n",
    "# 교차검증 진행\n",
    "# - return_train_score : 검증결과 반환받기\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs = -1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba633ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78e01b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23155241 0.49706658 0.27138101]\n"
     ]
    }
   ],
   "source": [
    "# 특성중요도\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c4a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "### oob 기능사용\n",
    "# 훈련에 참여하지 못한 잔여샘플 사용하는 기능\n",
    "# 기본은 사용한함\n",
    "rf = RandomForestClassifier(oob_score = True, n_jobs=-1,random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c077ce",
   "metadata": {},
   "source": [
    "## 엑스트라 트리(Extra Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783600b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 랜덤포레스트와 유사하게 작동\n",
    "# - 기본적으로 100개의 결정트리를 훈련\n",
    "# - 랜덤포레스트와의 차이점\n",
    "#   : 부트스트램 샘플링을 지원하지 않음\n",
    "#   : 훈련데이터 전체를 이용하여 결정트리를 생성\n",
    "#   : 무작위로 트리를 분리함\n",
    "# - 사용되는 속성 : splitter = 'random' 무작위속성\n",
    "# - 장점\n",
    "#   : 과대적합을 막고, 검증데이터의 평가 값을 높일 수 있음\n",
    "#   : 특성 데이터가 많지 않은 경우에는 랜덤포레스트와 큰 차이가 없음\n",
    "# - 랜덤포레스트는 불순도 등 여러가지 조건에 따라 결정트리를 생성하기 때문에 속도가 느린 반면\n",
    "# - 엑스트라트리는 랜덤하게 결정트리를 생성하기에 속도가 다소 빠르다는 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45d5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.1497252 , 0.15935373, 0.15935373, 0.17240953, 0.17241263]), 'score_time': array([0.03480339, 0.03099108, 0.03099108, 0.02692723, 0.02692676]), 'test_score': array([0.89128205, 0.89128205, 0.89938398, 0.88706366, 0.88295688]), 'train_score': array([0.99743392, 0.99692071, 0.99846075, 0.99820421, 0.99820421])}\n",
      "=============\n",
      "0.997844759088341 0.8903937240035804\n"
     ]
    }
   ],
   "source": [
    "### 사용패키지 : 랜덤포레스트와 동일\n",
    "# 사용되는 클래스(모델) : ExtraTreesClassifier()\n",
    "\n",
    "### 코어 전체사용, train 및 test 결과값 출력\n",
    "### 최종 train 및 test 결과 확인\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "et =  ExtraTreesClassifier(n_jobs = -1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs = -1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08642f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20702369 0.51313261 0.2798437 ]\n"
     ]
    }
   ],
   "source": [
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a94fe0",
   "metadata": {},
   "source": [
    "## 그레디언트 부스팅(Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10c7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 깊이(max_depth)가 얕은 결정트리를 사용함\n",
    "# - 기본적으로 max_depth = 3 사용\n",
    "# - 결정트리는 100개 사용\n",
    "### *** 기존에 다른 훈련모델의 결과가 좋지 않을 때 사용하는 모델 *** ###\n",
    "# 기존 훈련모델의 오차를 많이 보완해줌\n",
    "# 성능 향상을 위한 모델로 주로 사용\n",
    "# 과대적합에 강하고 일반화(과대/과소적합이 없는 상태)에 강함\n",
    "\n",
    "# 성능향상 테스트 방법\n",
    "# - 결정트리의 갯수를 조절하면서 테스트 진행\n",
    "# - 학습률을 지원하기 때문에 학습률의 값을 증가시키면서 테스트 진행\n",
    "#   : 기본 학습률은 0.1\n",
    "\n",
    "# 단점\n",
    "# - 순서대로 트리를 추가(랜덤x)하지 않기 때문에\n",
    "# - 훈련 속도는 느림\n",
    "# - 이런 느린 속도를 개선한 모델이\n",
    "#   히스토그램 기반 그레디언트 부스팅 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf6f18",
   "metadata": {},
   "source": [
    "### 그레디언트 부스팅 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e93be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.27227759, 0.2742753 , 0.28724003, 0.28823686, 0.28303766]), 'score_time': array([0.00299215, 0.00215602, 0.00199461, 0.00235224, 0.00199413]), 'test_score': array([0.86461538, 0.87794872, 0.88090349, 0.8613963 , 0.87268994]), 'train_score': array([0.89299461, 0.88555299, 0.88660852, 0.89276552, 0.88943048])}\n",
      "=============\n",
      "0.8894704231708938 0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "### 사용하는 클래스(모델) : GradientBoostingClassifier\n",
    "# 객체 생성시 아무것도 안주고 seed값만 \n",
    "# 교차검증시에는 train, test 결과값 출력\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs= -1)\n",
    "\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1cc3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12517641 0.73300095 0.14182264]\n",
      "0.8578461538461538\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)\n",
    "print(gb.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bec04f",
   "metadata": {},
   "source": [
    "### 학습률 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3580da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.23122787, 1.32029867, 1.36013174, 1.30635643, 1.28100109]), 'score_time': array([0.00598407, 0.01008248, 0.        , 0.00154972, 0.00614977]), 'test_score': array([0.88      , 0.88512821, 0.89527721, 0.862423  , 0.87577002]), 'train_score': array([0.95150115, 0.94842186, 0.94946126, 0.95177014, 0.95484864])}\n",
      "=============\n",
      "0.9512006117505237 0.879719686200179\n"
     ]
    }
   ],
   "source": [
    "# : 학습률이 커지면 트리 보정을 가하게 하기 때문에\n",
    "#   복잡한 모델을 만들어서 일반화 성능을 떨어트리게 됨\n",
    "# 학습률 : learning_rate = 0.1 -> 기본값\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators = 500,\n",
    "                                learning_rate = 0.2,\n",
    "                                random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs= -1)\n",
    "\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca7468",
   "metadata": {},
   "source": [
    "## 히스토그램기반 그레디언트 부스팅(Histogram-base Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146f8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.36045742, 0.33196592, 0.34485745, 0.38096833, 0.34948516]), 'score_time': array([0.01077628, 0.01095605, 0.01260805, 0.01201534, 0.01196885]), 'test_score': array([0.87179487, 0.89333333, 0.8973306 , 0.85934292, 0.88090349]), 'train_score': array([0.93815756, 0.93482166, 0.9374038 , 0.93945613, 0.94022576])}\n",
      "=============\n",
      "0.9380129799494501 0.8805410414363187\n"
     ]
    }
   ],
   "source": [
    "## 사용하는 클래스(모델) : HistGradientBoostingClassifier()\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs= -1)\n",
    "\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a38a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8584615384615385\n"
     ]
    }
   ],
   "source": [
    "hgb.fit(train_input, train_target)\n",
    "print(hgb.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd0932c",
   "metadata": {},
   "source": [
    "## 사이킷런 이외의 다른 패키지에서 지원하는\n",
    "## 히스토그램기반 그레디언트 부스팅 기능 모델들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc5363",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9ff2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
    "scores = cross_validate(xgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs= -1)\n",
    "\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847d5fd",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 마이크로소프트에서 만든 히스토그램 기반 그레디언트 부스트 패키지\n",
    "# - 훈련 속도가 매우 빠름\n",
    "# - 최신 기술을 많이 적용하고 잇어서 인기가 올라가는 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133f9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc600bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassfier(tree_method='hist', random_state=42)\n",
    "scores = cross_validate(lgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs= -1)\n",
    "\n",
    "print(scores)\n",
    "print('=============')\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08203819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ab31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
